{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vCL0JGCbUwi"
      },
      "source": [
        "# Inicialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa--cyvTWo_r"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "from PIL import Image # Install Pillow -> conda install anaconda::pillow or pip install pillow\n",
        "import os\n",
        "from skimage.io import  imread, imshow # Install scikit-image -> conda install scikit-image or pip install scikit-image\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics import confusion_matrix, balanced_accuracy_score,  mean_squared_error, r2_score, f1_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.functional import F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4vACqSHvkKo",
        "outputId": "cb383bf3-80d3-4aa1-f273-e6a5ff1642a0"
      },
      "outputs": [],
      "source": [
        "# Check if the code is running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    train_dataset_path = '/content/drive/MyDrive/Project1-AML/data-students/TRAIN'\n",
        "    test_dataset_path = '/content/drive/MyDrive/Project1-AML/data-students/TEST'\n",
        "else:\n",
        "    # Load data from local file\n",
        "    train_dataset_path = 'data-students/TRAIN'\n",
        "    test_dataset_path = 'data-students/TEST'\n",
        "\n",
        "# Now you can use file_path to load your data\n",
        "#print(\"File path:\", file_path)\n",
        "\n",
        "#FIXED VARIABLES\n",
        "IMG_WIDTH = 75\n",
        "IMG_HEIGHT = 75\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#testing variables\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rembg import remove\n",
        "import io\n",
        "\n",
        "def remove_background_pil(image):\n",
        "    # Convert PIL image to bytes\n",
        "    with io.BytesIO() as output_buffer:\n",
        "        image.save(output_buffer, format='PNG')\n",
        "        image_bytes = output_buffer.getvalue()\n",
        "\n",
        "    # Use rembg to remove the background\n",
        "    result = remove(image_bytes)\n",
        "\n",
        "    # Convert the result binary data back to a PIL image\n",
        "    result_image = Image.open(io.BytesIO(result))\n",
        "\n",
        "    # Fill transparent pixels with black\n",
        "    result_image = fill_transparent_pixels_with_black(result_image)\n",
        "\n",
        "    # Convert the image to RGB mode if it's not already\n",
        "    if result_image.mode != 'RGB':\n",
        "        result_image = result_image.convert('RGB')\n",
        "        \n",
        "    return result_image\n",
        "\n",
        "def fill_transparent_pixels_with_black(image):\n",
        "    # Convert image to RGBA mode if it's not already\n",
        "    if image.mode != 'RGBA':\n",
        "        image = image.convert('RGBA')\n",
        "\n",
        "    # Get the image data as a pixel access object\n",
        "    pixel_data = image.load()\n",
        "\n",
        "    # Iterate over each pixel\n",
        "    width, height = image.size\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            # Check if the pixel is transparent\n",
        "            if pixel_data[x, y][3] == 0:\n",
        "                # Set the pixel color to black (RGB: 0, 0, 0, Alpha: 255)\n",
        "                pixel_data[x, y] = (0, 0, 0, 255)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2\n",
        "\n",
        "# Define your custom transformation function\n",
        "augmentation = transforms.Compose([v2.RandomAffine(degrees=(-20, 20), translate=(0.1, 0.2), scale=(0.5, 0.9))])\n",
        "\n",
        "def removeBackground(image):\n",
        "    # Apply your custom background removal function\n",
        "    processed_image = remove_background_pil(image) # remove_background(removal_model, image)\n",
        "    \n",
        "    # Apply other transformations if needed\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    \n",
        "    return transform(processed_image)\n",
        "\n",
        "def Augment(image):\n",
        "    # Apply your custom background removal function\n",
        "    transform = transforms.Compose([\n",
        "        augmentation,\n",
        "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    \n",
        "    return transform(image)\n",
        "\n",
        "def input_transform(image):\n",
        "    # Apply your custom background removal function\n",
        "    transform = transforms.Compose([\n",
        "        augmentation,\n",
        "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    \n",
        "    return transform(image)\n",
        "\n",
        "normal_transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#COMBINE DATASET WITH RANDOMLY AUGMENTED DATASETS\n",
        "\n",
        "torch.cuda.is_available()\n",
        "True\n",
        "from torchvision.transforms import v2\n",
        "import shutil\n",
        "\n",
        "\n",
        "background_removed_path = 'data-students/TRAIN-NOBG'\n",
        "\n",
        "'''\n",
        "# Assuming you already have your original dataset and transformed dataset\n",
        "original_dataset = datasets.ImageFolder(root=train_dataset_path, transform=normal_transform)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(original_dataset, batch_size=None, shuffle=False)\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for image_path, target in original_dataset.imgs:\n",
        "    class_name = original_dataset.classes[target]\n",
        "    class_path = os.path.join(background_removed_path, class_name)\n",
        "    os.makedirs(class_path, exist_ok=True)\n",
        "    \n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Apply the transformation\n",
        "    transformed_image = removeBackground(image)\n",
        "    \n",
        "    # Save the transformed image in the corresponding class folder\n",
        "    image_filename = os.path.basename(image_path)\n",
        "    image_save_path = os.path.join(class_path, image_filename)\n",
        "    transformed_image_pil = transforms.ToPILImage()(transformed_image)\n",
        "    transformed_image_pil.save(image_save_path)  # Save the transformed image\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "nobg_dataset = datasets.ImageFolder(root=background_removed_path, transform=normal_transform)\n",
        "\n",
        "\n",
        "# Define how many times you want to enlarge the dataset\n",
        "enlarge_factor = 5\n",
        "\n",
        "# Create a list to hold the datasets\n",
        "combined_datasets = [nobg_dataset]\n",
        "\n",
        "# Add the transformed dataset to the list multiple times\n",
        "for _ in range(enlarge_factor):\n",
        "    transformed_dataset = datasets.ImageFolder(root=background_removed_path, transform=Augment)\n",
        "    combined_datasets.append(transformed_dataset)\n",
        "\n",
        "# Concatenate the datasets into a single dataset\n",
        "enlarged_dataset = ConcatDataset(combined_datasets)\n",
        "\n",
        "\n",
        "test_set_size = 0.4\n",
        "#get train & test for K-MEANS\n",
        "train_val_dataset, test_dataset = train_test_split(enlarged_dataset, test_size = test_set_size, random_state=seed) #random_state = randomizer seed\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(enlarged_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njIOwwsTdmsa"
      },
      "source": [
        "# Auxiliares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIbahDOdjdcU"
      },
      "outputs": [],
      "source": [
        "#to print the label (AUXILIAR)\n",
        "label_str = [\n",
        "    \"12 - Don't Go Left or Right\",\n",
        "    \"13 - Don't Go Right\",\n",
        "    \"24 - Go Right\",\n",
        "    \"37 - Children crossing\",\n",
        "    \"38 - Dangerous curve to the right\",\n",
        "    \"39 - Dangerous curve to the left\",\n",
        "    \"44 - Go left or straight\",\n",
        "    \"50 - Fences\",\n",
        "    \"6 - Speed limit (70km/h)\"\n",
        "]\n",
        "label_str_id = [\n",
        "    \"12\",\n",
        "    \"13\",\n",
        "    \"24\",\n",
        "    \"37\",\n",
        "    \"38\",\n",
        "    \"39\",\n",
        "    \"44\",\n",
        "    \"50\",\n",
        "    \"6\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def voting(trained_models,data_loader,type):\n",
        "    #type = 1 -> data loader with no labels (test folder)\n",
        "    #type = 0 -> data loader with labels\n",
        "    \n",
        "    n_splits = 5\n",
        "    #save the models\n",
        "    for i, model in enumerate(trained_models):\n",
        "        torch.save(model.state_dict(), f\"model_fold_{i}.pth\")\n",
        "\n",
        "    if type == 0: #data loader with labels\n",
        "        #pred matrix\n",
        "        predictions = []\n",
        "        for i in range(n_splits):\n",
        "            model = batch_norm_CNN()\n",
        "            model.load_state_dict(torch.load(f\"model_fold_{i}.pth\"))\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "            i = 0\n",
        "            with torch.no_grad():\n",
        "                    model_predictions = []\n",
        "\n",
        "                    for inputs, labels in data_loader:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        model_predictions.append(predicted)\n",
        "                    predictions_aux = torch.cat(model_predictions, dim=0).cpu()\n",
        "                    predictions.append(predictions_aux)\n",
        "\n",
        "        predictions_matrix = np.vstack(predictions)\n",
        "\n",
        "        #voting\n",
        "        num_classes = predictions_matrix.max() + 1\n",
        "\n",
        "        class_votes = np.zeros((num_classes, predictions_matrix.shape[1])) #(num_classes, num_predictions)\n",
        "\n",
        "        for col in range(predictions_matrix.shape[1]):\n",
        "            unique_classes, class_counts = np.unique(predictions_matrix[:, col], return_counts=True)\n",
        "            class_votes[unique_classes, col] = class_counts\n",
        "\n",
        "        most_voted_classes = np.argmax(class_votes, axis=0) #pred\n",
        "\n",
        "        #labels\n",
        "        full_dataset = []\n",
        "        for batch in data_loader:\n",
        "            inputs, labels = batch\n",
        "            full_dataset.append((inputs, labels))\n",
        "            y = torch.cat([labels for _, labels in full_dataset], dim=0) #labels\n",
        "\n",
        "        # evaluation\n",
        "        # Compute confusion matrix and F1 score\n",
        "    \n",
        "        conf_mat = confusion_matrix(y, most_voted_classes)\n",
        "        f1 = f1_score(y, most_voted_classes, average='weighted')\n",
        "        bal_acc = balanced_accuracy_score(y, most_voted_classes)\n",
        "        #precision = precision_score(y, most_voted_classes, average='weighted')\n",
        "        #recall = recall_score(y, most_voted_classes, average='weighted')\n",
        "\n",
        "        print('Confusion Matrix:\\n', conf_mat)\n",
        "        print('F1 Score: ', f1)\n",
        "        print('B_acc: ', bal_acc)\n",
        "        #print('Precision: ', precision)\n",
        "        #print('Recall: ', recall)\n",
        "\n",
        "        return y, most_voted_classes\n",
        "        \n",
        "    else: #from test folder - no labels\n",
        "        predictions = []\n",
        "        for i in range(n_splits):\n",
        "            model = batch_norm_CNN()\n",
        "            model.load_state_dict(torch.load(f\"model_fold_{i}.pth\"))\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "            i = 0\n",
        "            with torch.no_grad():\n",
        "                    model_predictions = []\n",
        "\n",
        "                    for i, inputs in enumerate(data_loader):\n",
        "                        inputs = inputs.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        predicted = torch.argmax(outputs, dim=1)\n",
        "                        model_predictions.append(predicted)\n",
        "                    predictions_aux = torch.cat(model_predictions, dim=0).cpu()\n",
        "                    predictions.append(predictions_aux)\n",
        "\n",
        "        predictions_matrix = np.vstack(predictions)\n",
        "\n",
        "        #voting\n",
        "        num_classes = predictions_matrix.max() + 1\n",
        "\n",
        "        class_votes = np.zeros((num_classes, predictions_matrix.shape[1])) #(num_classes, num_predictions)\n",
        "\n",
        "        for col in range(predictions_matrix.shape[1]):\n",
        "            unique_classes, class_counts = np.unique(predictions_matrix[:, col], return_counts=True)\n",
        "            class_votes[unique_classes, col] = class_counts\n",
        "\n",
        "        most_voted_classes = np.argmax(class_votes, axis=0) #pred\n",
        "         \n",
        "        return most_voted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhDXn_Xn-Eos"
      },
      "outputs": [],
      "source": [
        " # PREDICT TEST FOLDER AND CREATE CSV FILE ----------------------------------------------------\n",
        "\n",
        "def createCSV(model, test_dataset_loader,type, name):\n",
        "    import csv\n",
        "\n",
        "    data = []\n",
        "\n",
        "    #directory where you want to save the CSV file\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except ImportError:\n",
        "        IN_COLAB = False\n",
        "\n",
        "    if IN_COLAB:\n",
        "        save_dir = \"/content/drive/MyDrive/Project1-AML/Nic/\"\n",
        "    else:\n",
        "        #save_dir = r\"C:\\Users\\Nicoli Leal\\Desktop\\MEEC\\2 semestre\\Aprendizagem Computacional AvanÃ§ada\\Project-1\"\n",
        "        save_dir = \"/home/stefanotrenti/AML/project\"\n",
        "\n",
        "\n",
        "    #file name\n",
        "    csv_file = os.path.join(save_dir, name)\n",
        "\n",
        "    if type == \"voting\":\n",
        "      most_voted_classes = voting(model, test_dataset_loader,1)\n",
        "      for i in range(len(most_voted_classes)):\n",
        "        predicted_class = int(most_voted_classes[i])  # Extract the integer value\n",
        "        data.append({\"ID\": i+1, \"Class\": label_str_id[predicted_class]}) #, \"Name\": label_str[test_predictions]})\n",
        "\n",
        "    else:\n",
        "      for i, images in enumerate(test_dataset_loader):\n",
        "\n",
        "          images = images.to(device)\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          test_predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "          images = images.cpu().numpy()\n",
        "          predicted_classes = test_predictions.cpu().numpy()\n",
        "\n",
        "          # Iterate over the batch\n",
        "          predicted_class = int(predicted_classes[0])  # Extract the integer value\n",
        "          data.append({\"ID\": i+1, \"Class\": label_str_id[predicted_class]}) #, \"Name\": label_str[test_predictions]})\n",
        "\n",
        "\n",
        "    # Define the field names\n",
        "    fields = [\"ID\", \"Class\"]#, \"Name\"]\n",
        "\n",
        "    # Write data to CSV file\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=fields)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Write the data rows\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "    print(\"CSV file created successfully.\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPwOZytiwZMd"
      },
      "source": [
        "#EVALUATE FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgejPcIyXVOk"
      },
      "outputs": [],
      "source": [
        "# DEFINE EVALUATE FUNCTION\n",
        "def evaluate_network(model,dataset_loader, to_device=True):\n",
        "    # X given input data\n",
        "    # y corresponding target labels\n",
        "    full_dataset = []\n",
        "    for batch in dataset_loader:\n",
        "        # Assuming each batch is a tuple (inputs, labels)\n",
        "        inputs, labels = batch\n",
        "        full_dataset.append((inputs, labels))\n",
        "\n",
        "        # Concatenate all data points into a single tensor\n",
        "        X = torch.cat([inputs for inputs, _ in full_dataset], dim=0)\n",
        "        y = torch.cat([labels for _, labels in full_dataset], dim=0)\n",
        "\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    if to_device:\n",
        "      # Assuming you're using GPU (if available)\n",
        "      # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #model = model.to(device)\n",
        "\n",
        "    # Run the model on the test data\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Convert tensors to numpy arrays\n",
        "    if to_device:\n",
        "        predicted = predicted.to(\"cpu\")\n",
        "\n",
        "    predicted_np = predicted.cpu().numpy()\n",
        "    test_target_np = y.cpu().numpy()\n",
        "\n",
        "\n",
        "    # Compute confusion matrix and F1 score\n",
        "    conf_mat = confusion_matrix(test_target_np, predicted_np)\n",
        "    f1 = f1_score(test_target_np, predicted_np, average='weighted')\n",
        "    bal_acc = balanced_accuracy_score(y.cpu(), predicted_np)\n",
        "\n",
        "    #print('Confusion Matrix:\\n', conf_mat)\n",
        "    print('F1 Score: ', f1)\n",
        "    print('B_acc: ', bal_acc)\n",
        "\n",
        "    return conf_mat, f1, bal_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#TRAIN Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainCNN(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100. * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model, val_acc, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Train_K_FOLDS(k_model, epochs, lr, folds):\n",
        "    \n",
        "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
        "\n",
        "    models = []\n",
        "    index=0\n",
        "    i = 0\n",
        "    best_accuracy = 0\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(train_val_dataset)):\n",
        "\n",
        "        model = k_model()\n",
        "\n",
        "        #Creating DataLoaders for training and validation\n",
        "        train_sampler = torch.utils.data.SubsetRandomSampler(train_index)\n",
        "        val_sampler = torch.utils.data.SubsetRandomSampler(val_index)\n",
        "        #\n",
        "        train_loader = DataLoader(train_val_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "        val_loader = DataLoader(train_val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)\n",
        "\n",
        "        # Define your loss function and optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        # Train the model\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        trained_model, val_acc, val_loss = trainCNN(model, train_loader, val_loader, criterion, optimizer, epochs, device)\n",
        "        models.append(trained_model)\n",
        "        conf_matrix, F_score, bal_acc = evaluate_network(trained_model, val_loader)\n",
        "        if(val_acc > best_accuracy and bal_acc <1.1):\n",
        "            best_accuracy = val_acc\n",
        "            index = i\n",
        "            best_model = model\n",
        "\n",
        "        print(\"Best model has index \", index , \"\\n\")\n",
        "        \n",
        "    return best_model, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAIN THE MODEL WITH NO FOLDS\n",
        "def Train_NOFOLDS(model, epochs, lr):\n",
        "\n",
        "    nofolds_model = model()\n",
        "\n",
        "    train_dataset, val_dataset = train_test_split(train_val_dataset, test_size=0.1, random_state=seed) #random_state = randomizer seed\n",
        "\n",
        "    #Creating DataLoaders for training and validation\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "    # Define your loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(nofolds_model.parameters(), lr=lr)\n",
        "\n",
        "    # Train the nofolds_model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    nofolds_model, val_acc, val_loss = trainCNN(nofolds_model, train_loader, val_loader, criterion, optimizer, epochs, device)\n",
        "    conf_matrix, F_score, bal_acc = evaluate_network(nofolds_model, val_loader)\n",
        "    \n",
        "    return nofolds_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24b2DZWRXS1"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ukNFftJvTiz"
      },
      "outputs": [],
      "source": [
        "class batch_norm_CNN(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=9):\n",
        "        dpr = 0.1\n",
        "        super(batch_norm_CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            #input shape (BATCH_SIZE, 3, 75, 75)\n",
        "            nn.Conv2d(input_channels, out_channels = 12, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(12),\n",
        "            #output shape (BATCH_SIZE, 12, 75, 75)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), #add only ONE pooling layers (?) (image size too small -> we loose -spacial- information)\n",
        "            #outputa shape (BATCH_SIZE, 12, 37, 37)\n",
        "\n",
        "            #SECOND LAYER -----------------------------------------------------------\n",
        "            #input shape (BATCH_SIZE, 12, 37, 37)\n",
        "            nn.Conv2d(12, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            #output shape (BATCH_SIZE, 32, 37, 37)\n",
        "\n",
        "            #SECOND LAYER -----------------------------------------------------------\n",
        "            #input shape (BATCH_SIZE, 32, 37, 37)\n",
        "            nn.Conv2d(32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            #output shape (BATCH_SIZE, 64, 37, 37)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 37 * 37, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dpr),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(-1,64*37*37)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "    def print_architecture(self):\n",
        "        print(self)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class batch_norm_CNN_2L(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=9):\n",
        "        super(batch_norm_CNN_2L, self).__init__()        \n",
        "        self.conv1 = nn.Conv2d(input_channels, 20, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 12, kernel_size=3, padding = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "\n",
        "        # Output size calculation after max pooling:\n",
        "        # For each dimension, (input_size - kernel_size + 2*padding) / stride + 1\n",
        "        # For conv1: (75 - 3 + 2*1) / 1 + 1 = 75\n",
        "        # After max pooling: 75 / 2 = 37\n",
        "        # For conv2: (37 - 3 + 2*1) / 1 + 1 = 37\n",
        "        # After max pooling: 37 / 2 = 18 (rounded down)\n",
        "        self.fc1 = nn.Linear(18*18*12, 120)\n",
        "        self.fc2 = nn.Linear(120, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "\n",
        "        x = x.view(-1, self.fc1.in_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "    def print_architecture(self):\n",
        "        print(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class batch_norm_CNN_v2(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=9):\n",
        "        super(batch_norm_CNN_v2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 20, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 16, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(16, 12, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(12)\n",
        "        self.conv4 = nn.Conv2d(12, 8, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.fc1 = nn.Linear(18*18*8, 120)\n",
        "        self.fc2 = nn.Linear(120, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "\n",
        "        x = x.view(-1, self.fc1.in_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def print_architecture(self):\n",
        "        print(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class batch_norm_CNN_v3(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=9):\n",
        "        super(batch_norm_CNN_v3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 20, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 18, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(18)\n",
        "        self.conv3 = nn.Conv2d(18, 16, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.conv4 = nn.Conv2d(16, 14, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(14)\n",
        "        self.conv5 = nn.Conv2d(14, 12, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(12)\n",
        "        self.conv6 = nn.Conv2d(12, 8, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.fc1 = nn.Linear(9*9*8, 120)\n",
        "        self.fc2 = nn.Linear(120, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(F.relu(self.bn5(self.conv5(x))), 2)\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "\n",
        "        x = x.view(-1, self.fc1.in_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def print_architecture(self):\n",
        "        print(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class batch_norm_CNN_v4(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=9):\n",
        "        super(batch_norm_CNN_v4, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 20, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 18, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(18)\n",
        "        self.conv3 = nn.Conv2d(18, 16, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.conv4 = nn.Conv2d(16, 14, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(14)\n",
        "        self.conv5 = nn.Conv2d(14, 12, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(12)\n",
        "        self.conv6 = nn.Conv2d(12, 10, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(10)\n",
        "        self.conv7 = nn.Conv2d(10, 8, kernel_size=3, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(8)\n",
        "        self.conv8 = nn.Conv2d(8, 6, kernel_size=3, padding=1)\n",
        "        self.bn8 = nn.BatchNorm2d(6)\n",
        "\n",
        "        self.fc1 = nn.Linear(18*18*8, 120)\n",
        "        self.fc2 = nn.Linear(120, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.max_pool2d(F.relu(self.bn6(self.conv6(x))), 2)\n",
        "        x = F.relu(self.bn7(self.conv7(x)))\n",
        "        x = F.relu(self.bn8(self.conv8(x)))\n",
        "\n",
        "        x = x.view(-1, self.fc1.in_features)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def print_architecture(self):\n",
        "        print(self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Train - Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_v3, models_v3 = Train_K_FOLDS(batch_norm_CNN_v3, 40, 0.0001, 10)\n",
        "best_model_v2, models_v2 = Train_K_FOLDS(batch_norm_CNN_v2, 100, 0.0001, 10)\n",
        "best_model, models = Train_K_FOLDS(batch_norm_CNN, 100, 0.0001, 10)\n",
        "best_model_v4, models_v4 = Train_K_FOLDS(batch_norm_CNN_v4, 100, 0.0001, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"parameters\")\n",
        "print('learning rate  = ',learning_rate)\n",
        "print('Test set size  = ',test_set_size)\n",
        "print(\"enlarge_factor =\", enlarge_factor)\n",
        "print(\"number of folds =\", n_splits) \n",
        "print(\"with epochs =\", num_epochs)\n",
        "best_model.print_architecture()\n",
        "print(\" ----------------------------- evaluation of best model\")\n",
        "evaluate_network(best_model, test_loader)\n",
        "print(\"------------------------------ evaluation with voting\")\n",
        "voting(trained_models,test_loader,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Train - no Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nofolds_model_v3 = Train_NOFOLDS(batch_norm_CNN_v3, 30, 0.0001)\n",
        "nofolds_model_v2 = Train_NOFOLDS(batch_norm_CNN_v2, 30, 0.0001)\n",
        "nofolds_model = Train_NOFOLDS(batch_norm_CNN, 30, 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"parameters\")\n",
        "print('learning rate  = ',learning_rate)\n",
        "print('Test set size  = ',test_set_size)\n",
        "print(\"enlarge_factor =\", enlarge_factor)\n",
        "print(\"number of folds = none\") \n",
        "print(\"with epochs =\", num_epochs)\n",
        "nofolds_model.print_architecture() \n",
        "\n",
        "print(\" ------------------------- evaluation of model\")\n",
        "evaluate_network(nofolds_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PREDICT TEST FOLDER AND SAVE **CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def get_int(self, text):\n",
        "        return [int(c) if c.isdigit() else c for c in re.split('(\\d+)', text)]\n",
        "\n",
        "    def __init__(self, images_folder, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.image_files = [f for f in os.listdir(images_folder) if os.path.isfile(os.path.join(images_folder, f))]\n",
        "        self.image_files.sort(key=self.get_int)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.images_folder, self.image_files[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "    \n",
        "#run if we want to use new test folder every time we use csv\n",
        "'''\n",
        "transform_test = transforms.Compose([removeBackground,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "inference_dataset = TestDataset(images_folder=test_dataset_path, transform=transform_test)\n",
        "\n",
        "test_dataset_loader = DataLoader(inference_dataset, batch_size=1, shuffle=False)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ONLY RUN ONCE TO SAVE TEST IMAGES WITH NO BG IN FOLDER\n",
        "# Define input and output folders\n",
        "'''\n",
        "input_folder = 'data-students/TEST'\n",
        "output_folder = 'data-students/TEST-NOBG'\n",
        "\n",
        "#Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "#List all image files in the input folder\n",
        "image_files = [f for f in os.listdir(input_folder) if f.endswith(('png', 'jpg', 'jpeg', 'bmp'))]\n",
        "\n",
        "#Transformation to convert PIL image to tensor\n",
        "to_tensor = transforms.ToTensor()\n",
        "\n",
        "#Process each image\n",
        "for img_file in image_files:\n",
        "    #Load image\n",
        "    img_path = os.path.join(input_folder, img_file)\n",
        "    img = Image.open(img_path).convert('RGB')  \n",
        "\n",
        "    #Apply custom function\n",
        "    processed_img = removeBackground(img)\n",
        "\n",
        "    transformed_image_pil = transforms.ToPILImage()(processed_img)\n",
        "\n",
        "    #Save tensor as image with the same name\n",
        "    output_path = os.path.join(output_folder, img_file)\n",
        "    transformed_image_pil.save(output_path)\n",
        "\n",
        "print(\"All images processed and saved successfully.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#IF YOU WANT TO TAKE IMAGES FROM THE TEST FLDER WITH NO BG\n",
        "\n",
        "def input_transform(image):\n",
        "    # Apply your custom background removal function\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    \n",
        "    return transform(image)\n",
        "test_nobg_path = 'data-students/TEST-NOBG'\n",
        "\n",
        "inference_dataset = TestDataset(images_folder=test_nobg_path, transform=input_transform)\n",
        "\n",
        "test_dataset_loader = DataLoader(inference_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOk5yDG8rOAX",
        "outputId": "27813ae8-1f0d-4c0e-dee4-eef8ccefd477"
      },
      "outputs": [],
      "source": [
        "createCSV(nofolds_model, test_dataset_loader, [],\"predictions_CNN_noFolds.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYR1XJNKSH7i",
        "outputId": "b1e73eba-e8b1-4787-e951-8eef50fd6f49"
      },
      "outputs": [],
      "source": [
        "createCSV(best_model, test_dataset_loader,[],\"predictions_CNN_bst_model.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "createCSV(trained_models, test_dataset_loader,\"voting\",\"predictions_CNN_voting.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    \"\"\"\n",
        "    Denormalizes a tensor image.\n",
        "    Args:\n",
        "        tensor (Tensor): Tensor image of size (C, H, W) to be denormalized.\n",
        "        mean (sequence): Sequence of means for each channel.\n",
        "        std (sequence): Sequence of standard deviations for each channel.\n",
        "    Returns:\n",
        "        Tensor: Denormalized tensor image.\n",
        "    \"\"\"\n",
        "    mean = np.array(mean)\n",
        "    std = np.array(std)\n",
        "    denormalized_tensor = tensor.clone()\n",
        "    for t, m, s in zip(denormalized_tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return denormalized_tensor\n",
        "\n",
        "def save_images(loader, save_path):\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    batch_size = loader.batch_size\n",
        "\n",
        "    for i, batch in enumerate(loader):\n",
        "        for j, item in enumerate(batch):\n",
        "            if isinstance(item, tuple):\n",
        "                item = item[0]  # Assuming the image is the first element of the tuple\n",
        "            if len(item.shape) == 4:\n",
        "                # If the tensor has 4 dimensions (batch dimension included), iterate over the batch\n",
        "                for k, image_tensor in enumerate(item):\n",
        "                    denorm_image_tensor = denormalize(image_tensor)\n",
        "                    image_tensor = denorm_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "                    image = Image.fromarray((image_tensor * 255).astype(np.uint8))\n",
        "                    image.save(os.path.join(save_path, f'image_{i * batch_size + j * batch_size + k}.png'))\n",
        "            elif len(item.shape) == 3:\n",
        "                # If the tensor has 3 dimensions (no batch dimension), convert it directly\n",
        "                denorm_image_tensor = denormalize(item)\n",
        "                image_tensor = denorm_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "                image = Image.fromarray((image_tensor * 255).astype(np.uint8))\n",
        "                image.save(os.path.join(save_path, f'image_{i * batch_size + j}.png'))\n",
        "            elif len(item.shape) == 1:\n",
        "                # If the tensor has 1 dimension, it might be a label or other metadata, so skip it\n",
        "                pass\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected number of dimensions: {len(item.shape)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset, val_dataset = train_test_split(train_val_dataset, test_size=0.1, random_state=seed) #random_state = randomizer seed\n",
        "\n",
        "#Creating DataLoaders for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "# Save images from train_loader\n",
        "save_images(train_loader, 'train_images')\n",
        "\n",
        "# Save images from val_loader\n",
        "save_images(val_loader, 'val_images')\n",
        "\n",
        "# Save images from test_loader\n",
        "save_images(test_loader, 'test_images')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
